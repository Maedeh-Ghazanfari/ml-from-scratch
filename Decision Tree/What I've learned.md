Decision Tree is a non parametric algorithm -> It learns structure from the data itself (e.g., where to split based on feature values). Model complexity grows as data grows.

More flexible and can fit complex patterns, but can overfit if not controlled.


+Advantages:

Easy to interpret and visualize

Handles both categorical and numerical data

No need for feature scaling

Captures non-linear relationships

Can handle missing values and outliers well

-DisAdvantages:

Prone to overfitting (complex trees memorize noise)

Can be unstable — small changes in data can cause big changes in tree structure

Greedy algorithm — finds locally optimal splits, not guaranteed global optimum
